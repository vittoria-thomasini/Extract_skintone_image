{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vittoria-thomasini/Extract_skintone_image/blob/main/Extract_Skin_Tone_from_an_Image.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "RxymLTBIdt39"
      },
      "cell_type": "markdown",
      "source": [
        "# Extract Skin from and Image and Find the Dominant Colors/Tone\n",
        "\n",
        "If you are interested in testing out with code create a copy of this notebook and go to  menu on top \"Runtime -> Run All\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "BEV3cUoXr9GZ",
        "outputId": "52defbaa-b7ee-4c41-b121-deb92102228e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "5_UVMQ6PXD2y",
        "outputId": "c277f37c-4354-4a91-a281-5d511e90948c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install imutils\n",
        "!pip install xmltodict\n",
        "!pip install colormath"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imutils in /usr/local/lib/python3.10/dist-packages (0.5.4)\n",
            "Collecting xmltodict\n",
            "  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n",
            "Installing collected packages: xmltodict\n",
            "Successfully installed xmltodict-0.13.0\n",
            "Collecting colormath\n",
            "  Downloading colormath-3.0.0.tar.gz (39 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from colormath) (1.23.5)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.10/dist-packages (from colormath) (3.2.1)\n",
            "Building wheels for collected packages: colormath\n",
            "  Building wheel for colormath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for colormath: filename=colormath-3.0.0-py3-none-any.whl size=39405 sha256=e29785f51539ce8a16c5ff7973dd01f087dc604361aa5681cbebf5fa5dbf0800\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/b3/4d/c0738759c25a1df01958068f162cf2a9dc3ab1da8b972cfcfc\n",
            "Successfully built colormath\n",
            "Installing collected packages: colormath\n",
            "Successfully installed colormath-3.0.0\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "9NiJ0QKzeRxC"
      },
      "cell_type": "markdown",
      "source": [
        "##Importing Libraries\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "AuXA7RfbXOut"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from cv2 import imread\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn import cluster\n",
        "from collections import Counter\n",
        "import imutils\n",
        "from imutils import paths\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "import urllib3\n",
        "import csv\n",
        "import math\n",
        "from skimage import data\n",
        "import skimage.color"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZujqTVQEjxaM"
      },
      "cell_type": "markdown",
      "source": [
        "## Function to Extract Skin Color\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read files from github repository and create a local copy in real time to not be mandatory have the files in the machine.\n",
        "The files for nose and mouth identification are not from the official haarcascad repository but from a second one shared by the community link below."
      ],
      "metadata": {
        "id": "1Xy3_Qj55qlt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NOSE and MOUTH xml -> https://github.com/atduskgreg/opencv-processing/tree/master/lib/cascade-files"
      ],
      "metadata": {
        "id": "fjSb59dXA-8I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_file(url, name, extension):\n",
        "  file_url = url\n",
        "  http     = urllib3.PoolManager()\n",
        "  response = http.request('GET', file_url)\n",
        "  data     = response.data.decode('utf-8')\n",
        "  file_name = name + '.' + extension\n",
        "\n",
        "  with open(file_name, 'w') as arquivo:\n",
        "      arquivo.write(data)\n",
        "\n",
        "  file_path = '/content/'+ file_name\n",
        "\n",
        "  return file_path\n",
        "create_file('https://raw.githubusercontent.com/vittoria-thomasini/Extract_skintone_image/main/haarcascade/haarcascade_mcs_mouth.xml', 'haarcascade_mcs_mouth', 'xml')\n",
        "create_file('https://raw.githubusercontent.com/vittoria-thomasini/Extract_skintone_image/main/haarcascade/haarcascade_mcs_nose.xml', 'haarcascade_mcs_nose', 'xml')\n",
        "create_file('https://raw.githubusercontent.com/vittoria-thomasini/Extract_skintone_image/6ea08df8350b27a95f4856c710f5239279559413/mst-e_dataset_details.csv', 'dataset_details', 'csv')"
      ],
      "metadata": {
        "id": "-jknzwYa2-PL",
        "outputId": "e03edfc5-3a31-441f-a48d-9294f7c1e4a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/dataset_details.csv'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ***extractSkin*** function takes an 8 bit 3 channel image in the BGR colorspace. That is the format OpenCV reads color images  and returns the extracted image in same colorspace.\n",
        "\n",
        "The function works by using the** HSV colorspace** and uses thresholding (Thresholding is a process of filtering out pixel based on specified thresdhold parameter) to extracts pixel that corresponds to the skin color range,"
      ],
      "metadata": {
        "id": "IBv5TIiULhoA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def featuresIdentification(image):\n",
        "  global cropped_image\n",
        "\n",
        "  #Upload xml\n",
        "  mouth_xml = r'/content/haarcascade_mcs_mouth.xml'\n",
        "  nose_xml = r'/content/haarcascade_mcs_nose.xml'\n",
        "\n",
        "  #read xml\n",
        "  face_detector = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "  eye_detector = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
        "  mouth_detector = cv2.CascadeClassifier(mouth_xml)\n",
        "  nose_detector = cv2.CascadeClassifier(nose_xml)\n",
        "\n",
        "  #Convert image from BGR to GRAY\n",
        "  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Detect faces\n",
        "  faces = face_detector.detectMultiScale(gray,\n",
        "                                        scaleFactor=1.05,\n",
        "                                        minNeighbors=5)\n",
        "\n",
        "  # For each face\n",
        "  for (x, y, w, h) in faces:\n",
        "      # Draw rectangle around the face\n",
        "      cv2.rectangle(gray, (x, y), (x+w, y+h), (0, 0, 0), 2)\n",
        "      roi_face = gray[y:y+h, x:x+w]\n",
        "      cropped_image = image[y:y+h, x:x+w]\n",
        "      print(\"aqui crop FACE\")\n",
        "      plt.imshow(cropped_image)\n",
        "      plt.show()\n",
        "\n",
        "  if not cropped_image.any():\n",
        "    print(\"NÃ£o Identificado Rosto\")\n",
        "    cropped_image = gray\n",
        "\n",
        "  # Detect eye\n",
        "  eyes = eye_detector.detectMultiScale(cropped_image,\n",
        "                                       scaleFactor=1.05,\n",
        "                                       minNeighbors=5)\n",
        "  for (ex,ey,ew,eh) in eyes:\n",
        "      cv2.rectangle(cropped_image,(ex,ey),(ex+ew,ey+eh),(0,0,0),-2)\n",
        "\n",
        "\n",
        "  # Detect mouth\n",
        "  mouth = mouth_detector.detectMultiScale(cropped_image,\n",
        "                                       scaleFactor=1.05,\n",
        "                                       minNeighbors=5)\n",
        "  for (xm,ym,wm,hm) in mouth:\n",
        "      cv2.rectangle(cropped_image,(xm,ym),(xm+wm,ym+hm),(0,0,0),-2)\n",
        "\n",
        "  # Detect nose\n",
        "  nose = nose_detector.detectMultiScale(cropped_image,\n",
        "                                       scaleFactor=1.05,\n",
        "                                       minNeighbors=5)\n",
        "  for (xn,yn,wn,hn) in nose:\n",
        "      cv2.rectangle(cropped_image,(xn,yn),(xn+wn,yn+hn),(0,0,0),-2)\n",
        "\n",
        "  # Converting from BGR Colors Space to HSV\n",
        "  output =  cv2.cvtColor(cropped_image,cv2.COLOR_BGR2HSV)\n",
        "  plt.imshow(output)\n",
        "  plt.show()\n",
        "  return output\n"
      ],
      "metadata": {
        "id": "t9wconTY8iq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extractSkin(image):\n",
        "    # Takin image without features\n",
        "    img = featuresIdentification(image)\n",
        "\n",
        "    # Defining HSV Threadholds\n",
        "    lower_threshold = np.array([0, 48, 80], dtype=np.uint8)\n",
        "    upper_threshold = np.array([20, 255, 255], dtype=np.uint8)\n",
        "\n",
        "    # Single Channel mask,denoting presence of colors in the about threshold\n",
        "    skinMask = cv2.inRange(img, lower_threshold, upper_threshold)\n",
        "\n",
        "    # Cleaning up mask using Gaussian Filter\n",
        "    skinMask = cv2.GaussianBlur(skinMask, (3, 3), 0)\n",
        "\n",
        "    # Extracting skin from the threshold mask\n",
        "    skin = cv2.bitwise_and(img, img, mask=skinMask)\n",
        "\n",
        "    # Return the Skin image\n",
        "    return cv2.cvtColor(skin, cv2.COLOR_HSV2BGR)"
      ],
      "metadata": {
        "id": "Q0drbcom7pTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "El9UHDb7mvGR"
      },
      "cell_type": "markdown",
      "source": [
        "## Function to remove black pixels from extracted image\n",
        "\n",
        "The ***removeBlack*** function is more sort of the utility function to remove out the black pixel from the skin extracted. Since OpenCV by default doesn't handle transparent images and replaces those with zeros or black in color.\n",
        "\n",
        "This function is useful when thresholding is used in the image."
      ]
    },
    {
      "metadata": {
        "id": "ueCsY8mECI6Q"
      },
      "cell_type": "code",
      "source": [
        "def removeBlack(estimator_labels, estimator_cluster):\n",
        "\n",
        "  # Check for black\n",
        "  hasBlack = False\n",
        "\n",
        "  # Get the total number of occurance for each color\n",
        "  occurance_counter = Counter(estimator_labels)\n",
        "\n",
        "  # Quick lambda function to compare to lists\n",
        "  compare = lambda x, y: Counter(x) == Counter(y)\n",
        "\n",
        "  # Loop through the most common occuring color\n",
        "  for x in occurance_counter.most_common(len(estimator_cluster)):\n",
        "\n",
        "    # Quick List comprehension to convert each of RBG Numbers to int\n",
        "    color = [int(i) for i in estimator_cluster[x[0]].tolist() ]\n",
        "\n",
        "    # Check if the color is [0,0,0] that if it is black\n",
        "    if compare(color , [0,0,0]) == True:\n",
        "      # delete the occurance\n",
        "      del occurance_counter[x[0]]\n",
        "      # remove the cluster\n",
        "      hasBlack = True\n",
        "      estimator_cluster = np.delete(estimator_cluster,x[0],0)\n",
        "      break\n",
        "\n",
        "  return (occurance_counter,estimator_cluster,hasBlack)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gOMlAU75mtix"
      },
      "cell_type": "markdown",
      "source": [
        "## Extract Color Information\n",
        "\n",
        "The ***getColorInfomation*** function does all the heavy lifiting to make sense of prediction that came from the clustering.\n",
        "\n",
        "Taking the prediction labels (***estimator_labels***) and the cluster centroids(***estimator_cluster***) as the input and returns an array of dictionaries of the extracted colors.\n",
        "\n",
        "The function also takes an optional parameter (***hasThresholding***) to indicate whether a mask was used. This passed from the ***extractDominantColor*** function\n"
      ]
    },
    {
      "metadata": {
        "id": "ywktI_ISyoFj"
      },
      "cell_type": "code",
      "source": [
        "def getColorInformation(estimator_labels, estimator_cluster,hasThresholding=False):\n",
        "\n",
        "  # Variable to keep count of the occurance of each color predicted\n",
        "  occurance_counter = None\n",
        "\n",
        "  # Output list variable to return\n",
        "  colorInformation = []\n",
        "\n",
        "  #Check for Black\n",
        "  hasBlack =False\n",
        "\n",
        "  # If a mask has be applied, remove th black\n",
        "  if hasThresholding == True:\n",
        "\n",
        "    (occurance,cluster,black) = removeBlack(estimator_labels,estimator_cluster)\n",
        "    occurance_counter =  occurance\n",
        "    estimator_cluster = cluster\n",
        "    hasBlack = black\n",
        "\n",
        "  else:\n",
        "    occurance_counter = Counter(estimator_labels)\n",
        "\n",
        "  # Get the total sum of all the predicted occurances\n",
        "  totalOccurance = sum(occurance_counter.values())\n",
        "\n",
        "  # Loop through all the predicted colors\n",
        "  for x in occurance_counter.most_common(len(estimator_cluster)):\n",
        "\n",
        "    index = (int(x[0]))\n",
        "\n",
        "    # Quick fix for index out of bound when there is no threshold\n",
        "    index =  (index-1) if ((hasThresholding & hasBlack)& (int(index) !=0)) else index\n",
        "\n",
        "    # Get the color number into a list\n",
        "    color = estimator_cluster[index].tolist()\n",
        "\n",
        "    # Get the percentage of each color\n",
        "    color_percentage= (x[1]/totalOccurance)\n",
        "\n",
        "    #make the dictionay of the information\n",
        "    colorInfo = {\"cluster_index\":index , \"color\": color , \"color_percentage\" : color_percentage }\n",
        "\n",
        "    # Add the dictionary to the list\n",
        "    colorInformation.append(colorInfo)\n",
        "\n",
        "\n",
        "  return colorInformation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OyaNX8GHBsHN"
      },
      "cell_type": "markdown",
      "source": [
        "##  Putting it All together\n",
        "\n",
        "The ***extractDominantColor*** is the function that call the above function to output the information.\n",
        "\n",
        "The function take an 8 bit 3 channel BGR image as the input , the number of colors to be extracted.\n",
        "\n",
        "**KMeans Clustering*** is used to cluster the pixel data based on their RGB values.\n",
        "\n",
        "The function also takes an optional parameter (***hasThresholding***) to indicate whether a thresholding mask was used. This passed to the ***getColorInformation*** function\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "dwMgm-9k-pq6"
      },
      "cell_type": "code",
      "source": [
        "def extractDominantColor(image,number_of_colors=8,hasThresholding=False):\n",
        "\n",
        "  # Quick Fix Increase cluster counter to neglect the black(Read Article)\n",
        "  if hasThresholding == True:\n",
        "    number_of_colors +=1\n",
        "\n",
        "  # Taking Copy of the image\n",
        "  img = image.copy()\n",
        "\n",
        "  # Convert Image into RGB Colors Space\n",
        "  img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "\n",
        "  # Reshape Image change format without change content\n",
        "  img = img.reshape((img.shape[0]*img.shape[1]) , 3)\n",
        "\n",
        "  #Initiate KMeans Object\n",
        "  estimator = KMeans(n_clusters=number_of_colors, random_state=None, n_init='auto')\n",
        "\n",
        "  # Fit the image\n",
        "  estimator.fit(img)\n",
        "\n",
        "  # Get Color Information\n",
        "  colorInformation = getColorInformation(estimator.labels_,estimator.cluster_centers_,hasThresholding)\n",
        "  return colorInformation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jMgmvD0GI1Uh"
      },
      "cell_type": "markdown",
      "source": [
        "## Making a Visually Representation\n",
        "\n",
        "The ***plotColorBar*** function gives a visually representation of the extracted color information.\n",
        "\n",
        "Taking the color information (***colorInformation***) as input  and returns\n",
        " ***500x100 8 bit 3 channel BGR colorspace image***"
      ]
    },
    {
      "metadata": {
        "id": "fZtHRM0qn-SH"
      },
      "cell_type": "code",
      "source": [
        "def plotColorBar(colorInformation):\n",
        "\n",
        "  #Create a 500x100 black image\n",
        "  color_bar = np.zeros((100,500,3), dtype=\"uint8\")\n",
        "\n",
        "  top_x = 0\n",
        "  for x in colorInformation:\n",
        "    bottom_x = top_x + (x[\"color_percentage\"] * color_bar.shape[1])\n",
        "\n",
        "    color = tuple(map(int,(x['color'])))\n",
        "\n",
        "    cv2.rectangle(color_bar , (int(top_x),0) , (int(bottom_x),color_bar.shape[0]) ,color , -1)\n",
        "    top_x = bottom_x\n",
        "\n",
        "  #Check pergentage values\n",
        "  print('percentagem', x[\"color_percentage\"])\n",
        "\n",
        "  return color_bar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create CSV File\n",
        " Creating CSV file to save results calculated."
      ],
      "metadata": {
        "id": "5QUORFLA0wd6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#create CSV file header\n",
        "headerList = ['image_name', 'subject','pose', 'light', 'MST', 'MST_RGB', 'RGB', 'LAB','distancia_rgb','minimo_rgb', 'classificacao_indicada_rgb', 'distancia_lab', 'minimo_lab', 'classificacao_indicada_lab', 'acuracia']\n",
        "\n",
        "#create file with results\n",
        "with open('dataset_details_answer.csv', 'w', newline='') as file:\n",
        "    header = csv.DictWriter(file, delimiter=',', fieldnames=headerList)\n",
        "    header.writeheader()\n"
      ],
      "metadata": {
        "id": "uRjv1UI96_1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-uHKuSb2PM7V"
      },
      "cell_type": "markdown",
      "source": [
        "## Get Colors from Monk Pallete\n",
        "MST Swatches are 10 single-colored rectangles, and each swatch provides the most representative color within its MST group. The swatches are created for researchers who need to use the exact color values of the MST scale for their studies and for reference when running evaluations. Color format used is CIE-LAB, but its possible to use HEX, HSL, RGB and CIE-LCH. Can check information mentioned on https://skintone.google/get-started"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#select colors and split values to return\n",
        "def get_rgb_color(color):\n",
        "  rgb = []\n",
        "  df = pd.DataFrame.from_dict(color)\n",
        "  r = df.loc[0, 'color']\n",
        "  rgb = r\n",
        "  g = df.loc[1, 'color']\n",
        "  rgb = g\n",
        "  b = df.loc[2, 'color']\n",
        "  rgb = b\n",
        "  r = float(r)\n",
        "  g = float(g)\n",
        "  b = float(b)\n",
        "\n",
        "  return rgb, r, g, b"
      ],
      "metadata": {
        "id": "kzEWd_vIUdsA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get Distance between color detected and Monk Palette color"
      ],
      "metadata": {
        "id": "MHAvsTe5klFS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_distances(r, g, b):\n",
        "  list_distance = []\n",
        "  # else : #(mst == 1)\n",
        "  mst_rgb = \"246, 237, 228\"\n",
        "  mst_r = 246\n",
        "  mst_g = 237\n",
        "  mst_b = 228\n",
        "  distancia = math.sqrt(((mst_r - r)** 2) + ((mst_g - g)**2) + ((mst_b - b)**2))\n",
        "  list_distance.append(distancia)\n",
        "  # print(\"1\", distancia)\n",
        "  # elif (mst == 2):\n",
        "  mst_rgb = \"243, 231, 219\"\n",
        "  mst_r = 243\n",
        "  mst_g = 231\n",
        "  mst_b = 219\n",
        "  distancia = math.sqrt(((mst_r - r)** 2) + ((mst_g - g)**2) + ((mst_b - b)**2))\n",
        "  list_distance.append(distancia)\n",
        "  # print(\"2\", distancia)\n",
        "  # elif (mst == 3):\n",
        "  mst_rgb = \"247, 234, 208\"\n",
        "  mst_r = 247\n",
        "  mst_g = 234\n",
        "  mst_b = 208\n",
        "  distancia = math.sqrt(((mst_r - r)** 2) + ((mst_g - g)**2) + ((mst_b - b)**2))\n",
        "  list_distance.append(distancia)\n",
        "  # print(\"3\",distancia)\n",
        "  # elif (mst == 4):\n",
        "  mst_rgb = \"234, 218, 186\"\n",
        "  mst_r = 234\n",
        "  mst_g = 218\n",
        "  mst_b = 186\n",
        "  distancia = math.sqrt(((mst_r - r)** 2) + ((mst_g - g)**2) + ((mst_b - b)**2))\n",
        "  list_distance.append(distancia)\n",
        "  # print(\"4\",distancia)\n",
        "  # elif (mst == 5):\n",
        "  mst_rgb = \"215, 189, 150\"\n",
        "  mst_r = 215\n",
        "  mst_g = 189\n",
        "  mst_b = 150\n",
        "  distancia = math.sqrt(((mst_r - r)** 2) + ((mst_g - g)**2) + ((mst_b - b)**2))\n",
        "  list_distance.append(distancia)\n",
        "  print(\"5\",distancia)\n",
        "  # elif (mst == 6):\n",
        "  mst_rgb = \"160, 126, 86\"\n",
        "  mst_r = 160\n",
        "  mst_g = 126\n",
        "  mst_b = 86\n",
        "  distancia = math.sqrt(((mst_r - r)** 2) + ((mst_g - g)**2) + ((mst_b - b)**2))\n",
        "  list_distance.append(distancia)\n",
        "  # print(\"6\",distancia)\n",
        "  # elif (mst == 7):\n",
        "  mst_rgb = \"130, 92, 67\"\n",
        "  mst_r = 130\n",
        "  mst_g = 92\n",
        "  mst_b = 67\n",
        "  distancia = math.sqrt(((mst_r - r)** 2) + ((mst_g - g)**2) + ((mst_b - b)**2))\n",
        "  list_distance.append(distancia)\n",
        "  print(\"7\",distancia)\n",
        "  # elif (mst == 8):\n",
        "  mst_rgb = \"96, 65, 52\"\n",
        "  mst_r = 96\n",
        "  mst_g = 65\n",
        "  mst_b = 52\n",
        "  distancia = math.sqrt(((mst_r - r)** 2) + ((mst_g - g)**2) + ((mst_b - b)**2))\n",
        "  list_distance.append(distancia)\n",
        "  # print(\"8\",distancia)\n",
        "  # elif (mst == 9):\n",
        "  mst_rgb = \"58, 49, 42\"\n",
        "  mst_r = 58\n",
        "  mst_g = 49\n",
        "  mst_b = 42\n",
        "  distancia = math.sqrt(((mst_r - r)** 2) + ((mst_g - g)**2) + ((mst_b - b)**2))\n",
        "  list_distance.append(distancia)\n",
        "  # print(\"9\",distancia)\n",
        "  #  if(mst == 10):\n",
        "  mst_rgb = \"41, 36, 32\"\n",
        "  mst_r = 41\n",
        "  mst_g = 36\n",
        "  mst_b = 32\n",
        "  distancia = math.sqrt(((mst_r - r)** 2) + ((mst_g - g)**2) + ((mst_b - b)**2))\n",
        "  list_distance.append(distancia)\n",
        "  # print(\"10\", distancia)\n",
        "  return list_distance"
      ],
      "metadata": {
        "id": "Wji9heMfVfgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://python-colormath.readthedocs.io/en/latest/_modules/colormath/color_diff.html#delta_e_cie2000"
      ],
      "metadata": {
        "id": "F5FWaD_MkeI3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_lab_color(lab, mst):\n",
        "  list_distance_lab = []\n",
        "  list_distance_lab.clear()\n",
        "  #Monk Palette colors in Lab\n",
        "# else : #(mst == 1)\n",
        "  mst_lab = np.array([94.211, 1.503, 5.422])\n",
        "  distance_cie2000 = skimage.color.deltaE_ciede2000(mst_lab, lab)\n",
        "  list_distance_lab.append(distance_cie2000)\n",
        "  # print(\"1\",distance_cie2000)\n",
        "# elif (mst == 2):\n",
        "  mst_lab = np.array([92.275, 2.061, 7.28])\n",
        "  distance_cie2000 = skimage.color.deltaE_ciede2000(mst_lab, lab)\n",
        "  list_distance_lab.append(distance_cie2000)\n",
        "  # print(\"2\",distance_cie2000)\n",
        "# elif (mst == 3):\n",
        "  mst_lab = np.array([93.091, 0.216, 14.205])\n",
        "  distance_cie2000 = skimage.color.deltaE_ciede2000(mst_lab, lab)\n",
        "  list_distance_lab.append(distance_cie2000)\n",
        "  # print(\"3\",distance_cie2000)\n",
        "# elif (mst == 4):\n",
        "  mst_lab = np.array([87.573, 0.459, 17.748])\n",
        "  distance_cie2000 = skimage.color.deltaE_ciede2000(mst_lab, lab)\n",
        "  list_distance_lab.append(distance_cie2000)\n",
        "  # print(\"4\",distance_cie2000)\n",
        "# elif (mst == 5):\n",
        "  mst_lab = np.array([77.902, 3.471, 23.136])\n",
        "  distance_cie2000 = skimage.color.deltaE_ciede2000(mst_lab, lab)\n",
        "  list_distance_lab.append(distance_cie2000)\n",
        "  # print(\"5\",distance_cie2000)\n",
        "# elif (mst == 6):\n",
        "  mst_lab = np.array([55.142, 7.783, 26.74])\n",
        "  distance_cie2000 = skimage.color.deltaE_ciede2000(mst_lab, lab)\n",
        "  list_distance_lab.append(distance_cie2000)\n",
        "  # print(\"6\",distance_cie2000)\n",
        "# elif (mst == 7):\n",
        "  mst_lab = np.array([42.47, 12.325, 20.53])\n",
        "  distance_cie2000 = skimage.color.deltaE_ciede2000(mst_lab, lab)\n",
        "  list_distance_lab.append(distance_cie2000)\n",
        "  # print(\"7\",distance_cie2000)\n",
        "# elif (mst == 8):\n",
        "  mst_lab = np.array([30.678, 11.667, 13.335])\n",
        "  distance_cie2000 = skimage.color.deltaE_ciede2000(mst_lab, lab)\n",
        "  list_distance_lab.append(distance_cie2000)\n",
        "  # print(\"8\",distance_cie2000)\n",
        "# elif (mst == 9):\n",
        "  mst_lab = np.array([21.069, 2.69, 5.964])\n",
        "  distance_cie2000 = skimage.color.deltaE_ciede2000(mst_lab, lab)\n",
        "  list_distance_lab.append(distance_cie2000)\n",
        "  # print(\"9\",distance_cie2000)\n",
        " # if(mst == 10):\n",
        "  mst_lab = np.array([14.61, 1.482, 3.525])\n",
        "  distance_cie2000 = skimage.color.deltaE_ciede2000(mst_lab, lab)\n",
        "  list_distance_lab.append(distance_cie2000)\n",
        "  # print(\"10\",distance_cie2000)\n",
        "\n",
        "  return list_distance_lab"
      ],
      "metadata": {
        "id": "jAznr9GI95Ou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U7d_APvx9n4Z"
      },
      "cell_type": "code",
      "source": [
        "# Get Image from path\n",
        "path = (\"/content/drive/MyDrive/mst-e_data/subject_18/\")\n",
        "\n",
        "\n",
        " # Get Image from URL.\n",
        "input_image =  imutils.url_to_image(\"https://raw.githubusercontent.com/vittoria-thomasini/Extract_skintone_image/main/vittoria.jpeg\")\n",
        "\n",
        "imagePaths = list(paths.list_images(path))\n",
        "for imagePath in imagePaths:\n",
        "    input_image = cv2.imread(imagePath)\n",
        "    # print(imagePath)\n",
        "    # image = imutils.resize(input_image, width=250)\n",
        "    image = cv2.resize(input_image, (250,250))\n",
        "\n",
        "    #Show image\n",
        "    plt.imshow(cv2.cvtColor(image,cv2.COLOR_BGR2RGB))\n",
        "    plt.show()\n",
        "\n",
        "    # Apply Skin Mask\n",
        "    skin = extractSkin(image)\n",
        "\n",
        "    # Find the dominant color. Default is 1 , pass the parameter 'number_of_colors=N' where N is the specified number of colors\n",
        "    dominantColors = extractDominantColor(skin,hasThresholding=True)\n",
        "    if len(dominantColors) == 0:\n",
        "      print(\"Lista vazia!\")\n",
        "    else:\n",
        "      print(dominantColors[0])\n",
        "\n",
        "      #Show in the dominant color as bar\n",
        "      print(\"Color Bar\")\n",
        "      color_bar = plotColorBar(dominantColors)\n",
        "      plt.axis(\"off\")\n",
        "      plt.imshow(color_bar)\n",
        "      plt.show()\n",
        "\n",
        "      #check CSV created\n",
        "      dataset = pd.read_csv(\"/content/dataset_details.csv\")\n",
        "      #return values from csv\n",
        "      image_name = imagePath.replace(path, '')\n",
        "\n",
        "      #return first dominant color\n",
        "      color = dominantColors[0]\n",
        "      print( 'color',color)\n",
        "\n",
        "      #return rgb color from dominant color\n",
        "      rgb, r, g, b = get_rgb_color(color)\n",
        "      bgr = cv2.cvtColor( np.uint8([[rgb]] ), cv2.COLOR_RGB2BGR)[0][0]\n",
        "      lab = cv2.cvtColor( np.uint8([[bgr]] ), cv2.COLOR_BGR2LAB)[0][0]\n",
        "      print('lab', lab)\n",
        "\n",
        "      #return mst color Monk classification\n",
        "      img = dataset.loc[dataset['image_ID'] == image_name]\n",
        "      mst = pd.DataFrame.from_dict(img.MST)\n",
        "      mst = str(mst)\n",
        "      mst = mst[13:17]\n",
        "      mst = int(float(mst))\n",
        "      print('mst', mst)\n",
        "\n",
        "      #return subject information\n",
        "      subject = pd.DataFrame.from_dict(img.subject_name)\n",
        "      subject = str(subject)\n",
        "      subject = subject[20:33]\n",
        "      subject = subject.strip()\n",
        "      print('subject',subject)\n",
        "\n",
        "      #return light informaton\n",
        "      pose = pd.DataFrame.from_dict(img.pose)\n",
        "      pose = str(pose)\n",
        "      pose = pose[18:40]\n",
        "      pose2 = pose.strip()\n",
        "      print('pose', pose2)\n",
        "\n",
        "      #return light informaton\n",
        "      light = pd.DataFrame.from_dict(img.lighting)\n",
        "      light = str(light)\n",
        "      light = light[17:30]\n",
        "      light = light.strip()\n",
        "      print('light',light)\n",
        "\n",
        "      list_distance = []\n",
        "      list_distance = get_distances(r, g, b)\n",
        "\n",
        "      print(\"list\", list_distance)\n",
        "\n",
        "      minimo = min(list_distance)\n",
        "      print(\"minimo\",minimo)\n",
        "      classificacao_indicada = 0\n",
        "      classificacao_indicada = list_distance.index(minimo)\n",
        "      #adjust classification to correspond mast list\n",
        "      classificacao_indicada = classificacao_indicada + 1\n",
        "      print('indicado rgb:', classificacao_indicada)\n",
        "\n",
        "      classificacao_mst = 0\n",
        "      classificacao_mst = list_distance[mst-1]\n",
        "      print('classificao mst', classificacao_mst)\n",
        "\n",
        "      list_lab = []\n",
        "      list_lab = get_lab_color(lab, mst)\n",
        "      print('result_lab', list_lab)\n",
        "      minimo_lab = min(list_lab)\n",
        "      print(\"minimo\",minimo_lab)\n",
        "      classificacao_indicada_lab = 0\n",
        "      classificacao_indicada_lab = list_lab.index(minimo_lab)\n",
        "      #adjust classification to correspond mast list\n",
        "      classificacao_indicada_lab = classificacao_indicada_lab + 1\n",
        "      print('indicado lab:', classificacao_indicada_lab)\n",
        "\n",
        "      if (dataset.image_ID == image_name).any() == True:\n",
        "      #Monk Palette colors in RGB\n",
        "        if(mst == 10):\n",
        "          mst_rgb = \"41, 36, 32\"\n",
        "          mst_r = 41\n",
        "          mst_g = 36\n",
        "          mst_b = 32\n",
        "          mst_lab = np.array([14.61, 1.482, 3.525])\n",
        "        elif (mst == 9):\n",
        "          mst_rgb = \"58, 49, 42\"\n",
        "          mst_r = 58\n",
        "          mst_g = 49\n",
        "          mst_b = 42\n",
        "          mst_lab = np.array([21.069, 2.69, 5.964])\n",
        "        elif (mst == 8):\n",
        "          mst_rgb = \"96, 65, 52\"\n",
        "          mst_r = 96\n",
        "          mst_g = 65\n",
        "          mst_b = 52\n",
        "          mst_lab = np.array([30.678, 11.667, 13.335])\n",
        "        elif (mst == 7):\n",
        "          mst_rgb = \"130, 92, 67\"\n",
        "          mst_r = 130\n",
        "          mst_g = 92\n",
        "          mst_b = 67\n",
        "          mst_lab = np.array([42.47, 12.325, 20.53])\n",
        "        elif (mst == 6):\n",
        "          mst_rgb = \"160, 126, 86\"\n",
        "          mst_r = 160\n",
        "          mst_g = 126\n",
        "          mst_b = 86\n",
        "          mst_lab = np.array([55.142, 7.783, 26.74])\n",
        "        elif (mst == 5):\n",
        "          mst_rgb = \"215, 189, 150\"\n",
        "          mst_r = 215\n",
        "          mst_g = 189\n",
        "          mst_b = 150\n",
        "          mst_lab = np.array([77.902, 3.471, 23.136])\n",
        "        elif (mst == 4):\n",
        "          mst_rgb = \"234, 218, 186\"\n",
        "          mst_r = 234\n",
        "          mst_g = 218\n",
        "          mst_b = 186\n",
        "          mst_lab = np.array([87.573, 0.459, 17.748])\n",
        "        elif (mst == 3):\n",
        "          mst_rgb = \"247, 234, 208\"\n",
        "          mst_r = 247\n",
        "          mst_g = 234\n",
        "          mst_b = 208\n",
        "          mst_lab = np.array([93.091, 0.216, 14.205])\n",
        "        elif (mst == 2):\n",
        "          mst_rgb = \"243, 231, 219\"\n",
        "          mst_r = 243\n",
        "          mst_g = 231\n",
        "          mst_b = 219\n",
        "          mst_lab = np.array([92.275, 2.061, 7.28])\n",
        "        elif (mst == 1):\n",
        "          mst_rgb = \"246, 237, 228\"\n",
        "          mst_r = 246\n",
        "          mst_g = 237\n",
        "          mst_b = 228\n",
        "          mst_lab = np.array([94.211, 1.503, 5.422])\n",
        "      distance_rgb = math.sqrt(((mst_r - r)** 2) + ((mst_g - g)**2) + ((mst_b - b)**2))\n",
        "      distance_lab = skimage.color.deltaE_ciede2000(mst_lab, lab)\n",
        "      print('distance rgb',distance_rgb)\n",
        "      print('distance lab',distance_lab)\n",
        "\n",
        "      accuracy = round(100 - abs(distance_lab - minimo_lab), 2)\n",
        "      print(accuracy, 'accuracy')\n",
        "\n",
        "      with open('dataset_details_answer.csv', 'a', newline='') as file:\n",
        "          writer = csv.writer(file)\n",
        "          writer.writerow([image_name, subject, pose, light, mst, mst_rgb, rgb, lab, distance_rgb, minimo, classificacao_indicada, distance_lab, minimo_lab, classificacao_indicada_lab, accuracy])\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}