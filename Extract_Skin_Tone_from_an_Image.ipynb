{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vittoria-thomasini/Extract_skintone_image/blob/main/Extract_Skin_Tone_from_an_Image.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "RxymLTBIdt39"
      },
      "cell_type": "markdown",
      "source": [
        "# How to extract Skin from and Image and Find the Dominant Colours/Tone\n",
        "\n",
        "This the online notebook containing the explaination of the code for the article found at https://goo.gl/bpkVn3\n",
        "\n",
        "If you are interested in testing out with code create a copy of this notebook and go to  menu on top \"Runtime -> Run All\"\n"
      ]
    },
    {
      "metadata": {
        "id": "5_UVMQ6PXD2y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff626610-5819-4a0b-88f5-027641d82fd4"
      },
      "cell_type": "code",
      "source": [
        "!pip install imutils\n",
        "!pip install xmltodict\n",
        "!pip install colormath"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imutils in /usr/local/lib/python3.10/dist-packages (0.5.4)\n",
            "Requirement already satisfied: xmltodict in /usr/local/lib/python3.10/dist-packages (0.13.0)\n",
            "Requirement already satisfied: colormath in /usr/local/lib/python3.10/dist-packages (3.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from colormath) (1.23.5)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.10/dist-packages (from colormath) (3.1)\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "9NiJ0QKzeRxC"
      },
      "cell_type": "markdown",
      "source": [
        "## Section One : Importing Libraries\n",
        "\n",
        " - **numpy** : OpenCV uses Numpy for numerical operation. Hence Numpy is used to align input with the respective data type\n",
        "\n",
        " - **cv2** : OpenCV used for image processing\n",
        "\n",
        " - **Counter** : Useful for counting labels\n",
        "\n",
        " - **imutils** :  Useful utilities for image processing\n",
        "\n",
        " - **pprint** :  Library to pretty print data\n",
        "\n",
        " - **matplotlib** :  Normally used as a graph plotting lirbary , but we will use it show inline images since \"cv2.imshow\" doesn't work on collab\n",
        "\n",
        " - **pandas** :\n",
        " - **urllib** :"
      ]
    },
    {
      "metadata": {
        "id": "AuXA7RfbXOut"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.cluster import KMeans\n",
        "from collections import Counter\n",
        "import imutils\n",
        "import pprint\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "import urllib.request"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MST Swatches are 10 single-colored rectangles, and each swatch provides the most representative color within its MST group. The swatches are created for researchers who need to use the exact color values of the MST scale for their studies and for reference when running evaluations.\n",
        "Color format used is CIE-LAB, but its possible to use HEX, HSL, RGB and CIE-LCH.\n",
        "Can check information mentioned on https://skintone.google/get-started"
      ],
      "metadata": {
        "id": "4TYpZVG8nWm-"
      }
    },
    {
      "metadata": {
        "id": "ZujqTVQEjxaM"
      },
      "cell_type": "markdown",
      "source": [
        "## Section Two.1 : Function to Extract Skin Color\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read files from github repository and create a local copy in real time to not be mandatory have the files in the machine.\n",
        "The files for nose and mouth identification are not from the official haarcascad repository but from a second one shared by the community link below."
      ],
      "metadata": {
        "id": "1Xy3_Qj55qlt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NOSE and MOUTH xml -> https://github.com/atduskgreg/opencv-processing/tree/master/lib/cascade-files"
      ],
      "metadata": {
        "id": "fjSb59dXA-8I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import urllib3\n",
        "def create_file(url, name, extension):\n",
        "  file_url = url\n",
        "  http     = urllib3.PoolManager()\n",
        "  response = http.request('GET', file_url)\n",
        "  data     = response.data.decode('utf-8')\n",
        "  file_name = name + '.' + extension\n",
        "\n",
        "  with open(file_name, 'w') as arquivo:\n",
        "      arquivo.write(data)\n",
        "\n",
        "  file_path = '/content/'+ file_name\n",
        "\n",
        "  return file_path\n",
        "create_file('https://raw.githubusercontent.com/vittoria-thomasini/Extract_skintone_image/main/haarcascade/haarcascade_mcs_mouth.xml', 'haarcascade_mcs_mouth', 'xml')\n",
        "create_file('https://raw.githubusercontent.com/vittoria-thomasini/Extract_skintone_image/main/haarcascade/haarcascade_mcs_nose.xml', 'haarcascade_mcs_nose', 'xml')\n",
        "create_file('https://raw.githubusercontent.com/vittoria-thomasini/Extract_skintone_image/6ea08df8350b27a95f4856c710f5239279559413/mst-e_dataset_details.csv', 'dataset_details', 'csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "-jknzwYa2-PL",
        "outputId": "063bb9fb-8abd-4945-f44b-3fc92653d772"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/dataset_details.csv'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ***extractSkin*** function takes an 8 bit 3 channel image in the BGR colorspace (as mentioned in the article this is how OpenCV reads color images) and returns the extracted image in same colorspace.\n",
        "\n",
        "The function works by using the** HSV colorspace** and uses thresholding (Thresholding is a process of filtering out pixel based on specified thresdhold parameter) to extracts pixel that corresponds to the skin color range,"
      ],
      "metadata": {
        "id": "IBv5TIiULhoA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def featuresIdentification(image):\n",
        "  global cropped_image\n",
        "\n",
        "  #Upload xml\n",
        "  mouth_xml = r'/content/haarcascade_mcs_mouth.xml'\n",
        "  nose_xml = r'/content/haarcascade_mcs_nose.xml'\n",
        "\n",
        "  #read xml\n",
        "  face_detector = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "  eye_detector = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
        "  mouth_detector = cv2.CascadeClassifier(mouth_xml)\n",
        "  nose_detector = cv2.CascadeClassifier(nose_xml)\n",
        "\n",
        "  #Convert image from BGR to GRAY\n",
        "  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Detect faces\n",
        "  faces = face_detector.detectMultiScale(gray,\n",
        "                                        scaleFactor=1.05,\n",
        "                                        minNeighbors=5)\n",
        "\n",
        "  # For each face\n",
        "  for (x, y, w, h) in faces:\n",
        "      # Draw rectangle around the face\n",
        "      cv2.rectangle(gray, (x, y), (x+w, y+h), (0, 0, 0), 2)\n",
        "      roi_face = gray[y:y+h, x:x+w]\n",
        "      cropped_image = image[y:y+h, x:x+w]\n",
        "      print(\"aqui crop FACE\")\n",
        "      plt.imshow(cropped_image)\n",
        "      plt.show()\n",
        "\n",
        "  if not cropped_image.any():\n",
        "    print(\"NÃ£o Identificado Rosto\")\n",
        "    cropped_image = gray\n",
        "  # Detect eye\n",
        "  eyes = eye_detector.detectMultiScale(cropped_image,\n",
        "                                       scaleFactor=1.05,\n",
        "                                       minNeighbors=5)\n",
        "  for (ex,ey,ew,eh) in eyes:\n",
        "      cv2.rectangle(cropped_image,(ex,ey),(ex+ew,ey+eh),(0,0,0),-2)\n",
        "      # cropped_image = img[y:y+h, x:x+w]\n",
        "      # roi_eye = roi_face[y:y+h, x:x+w]\n",
        "\n",
        "  # Detect mouth\n",
        "  mouth = mouth_detector.detectMultiScale(cropped_image,\n",
        "                                       scaleFactor=1.05,\n",
        "                                       minNeighbors=5)\n",
        "  for (xm,ym,wm,hm) in mouth:\n",
        "      cv2.rectangle(cropped_image,(xm,ym),(xm+wm,ym+hm),(0,0,0),-2)\n",
        "      # cropped_image = image[y:y+h, x:x+w]\n",
        "      # roi_mouth = roi_face[y:y+h, x:x+w]\n",
        "  # print(\"aqui crop BOCA\")\n",
        "  # plt.imshow(cropped_image)\n",
        "  # plt.show()\n",
        "\n",
        "  # Detect nose\n",
        "  nose = nose_detector.detectMultiScale(cropped_image,\n",
        "                                       scaleFactor=1.05,\n",
        "                                       minNeighbors=5)\n",
        "  for (xn,yn,wn,hn) in nose:\n",
        "      cv2.rectangle(cropped_image,(xn,yn),(xn+wn,yn+hn),(0,0,0),-2)\n",
        "      # cropped_image = image[y:y+h, x:x+w]\n",
        "      # roi_nose = roi_face[y:y+h, x:x+w]\n",
        "      # print(\"cropped image in nose\")\n",
        "      # plt.imshow(cropped_image)\n",
        "      # plt.show()\n",
        "\n",
        "  # Converting from BGR Colours Space to HSV\n",
        "  output =  cv2.cvtColor(cropped_image,cv2.COLOR_BGR2HSV)\n",
        "  plt.imshow(output)\n",
        "  plt.show()\n",
        "  return output\n"
      ],
      "metadata": {
        "id": "t9wconTY8iq4"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extractSkin(image):\n",
        "    # Takin image without features\n",
        "    img = featuresIdentification(image)\n",
        "\n",
        "    # Defining HSV Threadholds\n",
        "    lower_threshold = np.array([0, 48, 80], dtype=np.uint8)\n",
        "    upper_threshold = np.array([20, 255, 255], dtype=np.uint8)\n",
        "\n",
        "    # Single Channel mask,denoting presence of colours in the about threshold\n",
        "    skinMask = cv2.inRange(img, lower_threshold, upper_threshold)\n",
        "\n",
        "    # Cleaning up mask using Gaussian Filter\n",
        "    skinMask = cv2.GaussianBlur(skinMask, (3, 3), 0)\n",
        "\n",
        "    # Extracting skin from the threshold mask\n",
        "    skin = cv2.bitwise_and(img, img, mask=skinMask)\n",
        "\n",
        "    # Return the Skin image\n",
        "    return cv2.cvtColor(skin, cv2.COLOR_HSV2BGR)"
      ],
      "metadata": {
        "id": "Q0drbcom7pTJ"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "metadata": {
        "id": "El9UHDb7mvGR"
      },
      "cell_type": "markdown",
      "source": [
        "## Section Two.2 :  Function to remove black pixels from extracted image\n",
        "\n",
        "The ***removeBlack*** function is more sort of the utility function to remove out the black pixel from the skin extracted. Since OpenCV by default doesn't handle transparent images and replaces those with zeros(black in color word).\n",
        "\n",
        "This function is useful when thresholding is used in the image."
      ]
    },
    {
      "metadata": {
        "id": "ueCsY8mECI6Q"
      },
      "cell_type": "code",
      "source": [
        "def removeBlack(estimator_labels, estimator_cluster):\n",
        "\n",
        "  # Check for black\n",
        "  hasBlack = False\n",
        "\n",
        "  # Get the total number of occurance for each color\n",
        "  occurance_counter = Counter(estimator_labels)\n",
        "\n",
        "  # Quick lambda function to compare to lists\n",
        "  compare = lambda x, y: Counter(x) == Counter(y)\n",
        "\n",
        "  # Loop through the most common occuring color\n",
        "  for x in occurance_counter.most_common(len(estimator_cluster)):\n",
        "\n",
        "    # Quick List comprehension to convert each of RBG Numbers to int\n",
        "    color = [int(i) for i in estimator_cluster[x[0]].tolist() ]\n",
        "\n",
        "    # Check if the color is [0,0,0] that if it is black\n",
        "    if compare(color , [0,0,0]) == True:\n",
        "      # delete the occurance\n",
        "      del occurance_counter[x[0]]\n",
        "      # remove the cluster\n",
        "      hasBlack = True\n",
        "      estimator_cluster = np.delete(estimator_cluster,x[0],0)\n",
        "      break\n",
        "\n",
        "  return (occurance_counter,estimator_cluster,hasBlack)"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gOMlAU75mtix"
      },
      "cell_type": "markdown",
      "source": [
        "## Section Two.3 : Extract Colour Information\n",
        "\n",
        "The ***getColorInfomation*** function does all the heavy lifiting to make sense of prediction that came from the clustering.\n",
        "\n",
        "Taking the prediction labels (***estimator_labels***) and the cluster centroids(***estimator_cluster***) as the input and returns an array of dictionaries of the extracted colours.\n",
        "\n",
        "The function also takes an optional parameter (***hasThresholding***) to indicate whether a mask was used. This passed from the ***extractDominantColor*** function\n"
      ]
    },
    {
      "metadata": {
        "id": "ywktI_ISyoFj"
      },
      "cell_type": "code",
      "source": [
        "def getColorInformation(estimator_labels, estimator_cluster,hasThresholding=False):\n",
        "\n",
        "  # Variable to keep count of the occurance of each color predicted\n",
        "  occurance_counter = None\n",
        "\n",
        "  # Output list variable to return\n",
        "  colorInformation = []\n",
        "\n",
        "\n",
        "  #Check for Black\n",
        "  hasBlack =False\n",
        "\n",
        "  # If a mask has be applied, remove th black\n",
        "  if hasThresholding == True:\n",
        "\n",
        "    (occurance,cluster,black) = removeBlack(estimator_labels,estimator_cluster)\n",
        "    occurance_counter =  occurance\n",
        "    estimator_cluster = cluster\n",
        "    hasBlack = black\n",
        "\n",
        "  else:\n",
        "    occurance_counter = Counter(estimator_labels)\n",
        "\n",
        "  # Get the total sum of all the predicted occurances\n",
        "  totalOccurance = sum(occurance_counter.values())\n",
        "\n",
        "\n",
        "  # Loop through all the predicted colors\n",
        "  for x in occurance_counter.most_common(len(estimator_cluster)):\n",
        "\n",
        "    index = (int(x[0]))\n",
        "\n",
        "    # Quick fix for index out of bound when there is no threshold\n",
        "    index =  (index-1) if ((hasThresholding & hasBlack)& (int(index) !=0)) else index\n",
        "\n",
        "    # Get the color number into a list\n",
        "    color = estimator_cluster[index].tolist()\n",
        "\n",
        "    # Get the percentage of each color\n",
        "    color_percentage= (x[1]/totalOccurance)\n",
        "\n",
        "    #make the dictionay of the information\n",
        "    colorInfo = {\"cluster_index\":index , \"color\": color , \"color_percentage\" : color_percentage }\n",
        "\n",
        "    # Add the dictionary to the list\n",
        "    colorInformation.append(colorInfo)\n",
        "\n",
        "\n",
        "  return colorInformation"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OyaNX8GHBsHN"
      },
      "cell_type": "markdown",
      "source": [
        "## Section Two.4 : Putting it All together\n",
        "\n",
        "The ***extractDominantColor*** is the function that call the above function to output the information.\n",
        "\n",
        "The function take an 8 bit 3 channel BGR image as the input , the number of colors to be extracted. This does all the super heavy lifting by sparkling some magic power of machine learning.\n",
        "\n",
        "\n",
        "As mention in the article , An unsupervised clustering algorithm, ***KMeans Clustering*** is used to cluster the pixel data based on their RGB values.\n",
        "\n",
        "\n",
        "The function also takes an optional parameter (***hasThresholding***) to indicate whether a thresholding mask was used. This passed to the ***getColorInformation*** function\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "img.reshape tem o papel de mudar o formato do array sem mudar o conteudo"
      ],
      "metadata": {
        "id": "FPh35W5Sx3ZK"
      }
    },
    {
      "metadata": {
        "id": "dwMgm-9k-pq6"
      },
      "cell_type": "code",
      "source": [
        "from sklearn import cluster\n",
        "\n",
        "def extractDominantColor(image,number_of_colors=10,hasThresholding=False):\n",
        "\n",
        "  # Quick Fix Increase cluster counter to neglect the black(Read Article)\n",
        "  if hasThresholding == True:\n",
        "    number_of_colors +=1\n",
        "\n",
        "  # Taking Copy of the image\n",
        "  img = image.copy()\n",
        "\n",
        "  # Convert Image into RGB Colours Space\n",
        "  img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "\n",
        "  # Reshape Image\n",
        "  img = img.reshape((img.shape[0]*img.shape[1]) , 3)\n",
        "\n",
        "  #Initiate KMeans Object\n",
        "  estimator = KMeans(n_clusters=number_of_colors, random_state=None, n_init='auto')\n",
        "\n",
        "  # Fit the image\n",
        "  estimator.fit(img)\n",
        "\n",
        "  # Get Colour Information\n",
        "  colorInformation = getColorInformation(estimator.labels_,estimator.cluster_centers_,hasThresholding)\n",
        "  return colorInformation"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jMgmvD0GI1Uh"
      },
      "cell_type": "markdown",
      "source": [
        "## Section Two.4.1 : Putting it All together: Making a Visually Representation\n",
        "\n",
        "The ***plotColorBar*** function gives a visually representation of the extracted color information.\n",
        "\n",
        "Taking the color information (***colorInformation***) as input  and returns\n",
        " ***500x100 8 bit 3 channel BGR colorspace image***"
      ]
    },
    {
      "metadata": {
        "id": "fZtHRM0qn-SH"
      },
      "cell_type": "code",
      "source": [
        "def plotColorBar(colorInformation):\n",
        "  #Create a 500x100 black image\n",
        "  color_bar = np.zeros((100,500,3), dtype=\"uint8\")\n",
        "\n",
        "  top_x = 0\n",
        "  for x in colorInformation:\n",
        "    bottom_x = top_x + (x[\"color_percentage\"] * color_bar.shape[1])\n",
        "\n",
        "    color = tuple(map(int,(x['color'])))\n",
        "\n",
        "    cv2.rectangle(color_bar , (int(top_x),0) , (int(bottom_x),color_bar.shape[0]) ,color , -1)\n",
        "    top_x = bottom_x\n",
        "\n",
        "  return color_bar"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f3xdAIqTOwuU"
      },
      "cell_type": "markdown",
      "source": [
        "## Section Two.4.2 : Putting it All together: Pretty Print\n",
        "\n",
        "The function makes print out the color information in a readable manner"
      ]
    },
    {
      "metadata": {
        "id": "YV3vAwHG-B8l"
      },
      "cell_type": "code",
      "source": [
        "def prety_print_data(color_info):\n",
        "  for x in color_info:\n",
        "    print(pprint.pformat(x))"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating CVS file to save results calculated."
      ],
      "metadata": {
        "id": "5QUORFLA0wd6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#create CSV file\n",
        "import csv\n",
        "headerList = ['image_name', 'subject', 'light', 'MST', 'MST_RGB', 'RGB', 'LAB','distancia_rgb','minimo_rgb', 'classificacao_indicada_rgb', 'distancia_lab', 'minimo_lab', 'classificacao_indicada_lab']\n",
        "\n",
        "with open('dataset_details_answer.csv', 'w', newline='') as file:\n",
        "    header = csv.DictWriter(file, delimiter=',', fieldnames=headerList)\n",
        "    header.writeheader()\n"
      ],
      "metadata": {
        "id": "uRjv1UI96_1e"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-uHKuSb2PM7V"
      },
      "cell_type": "markdown",
      "source": [
        "## Section Three: Baking the Pie\n",
        "The below lines of code, is the implementation of the above defined function."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_rgb_color(color):\n",
        "  rgb = []\n",
        "  df = pd.DataFrame.from_dict(color)\n",
        "  r = df.loc[0, 'color']\n",
        "  rgb = r\n",
        "  g = df.loc[1, 'color']\n",
        "  rgb = g\n",
        "  b = df.loc[2, 'color']\n",
        "  rgb = b\n",
        "  r = float(r)\n",
        "  g = float(g)\n",
        "  b = float(b)\n",
        "\n",
        "  return rgb, r, g, b"
      ],
      "metadata": {
        "id": "kzEWd_vIUdsA"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import math\n",
        "list_distance = []\n",
        "\n",
        "def get_distances(r, g, b):\n",
        "  # else : #(mst == 1)\n",
        "  mst_rgb = \"246, 237, 228\"\n",
        "  mst_r = 246\n",
        "  mst_g = 237\n",
        "  mst_b = 228\n",
        "  distancia = math.sqrt(((mst_r - r)** 2) + ((mst_g - g)**2) + ((mst_b - b)**2))\n",
        "  list_distance.append(distancia)\n",
        "  print(\"1\", distancia)\n",
        "  # elif (mst == 2):\n",
        "  mst_rgb = \"243, 231, 219\"\n",
        "  mst_r = 243\n",
        "  mst_g = 231\n",
        "  mst_b = 219\n",
        "  distancia = math.sqrt(((mst_r - r)** 2) + ((mst_g - g)**2) + ((mst_b - b)**2))\n",
        "  list_distance.append(distancia)\n",
        "  print(\"2\", distancia)\n",
        "  # elif (mst == 3):\n",
        "  mst_rgb = \"247, 234, 208\"\n",
        "  mst_r = 247\n",
        "  mst_g = 234\n",
        "  mst_b = 208\n",
        "  distancia = math.sqrt(((mst_r - r)** 2) + ((mst_g - g)**2) + ((mst_b - b)**2))\n",
        "  list_distance.append(distancia)\n",
        "  print(\"3\",distancia)\n",
        "  # elif (mst == 4):\n",
        "  mst_rgb = \"234, 218, 186\"\n",
        "  mst_r = 234\n",
        "  mst_g = 218\n",
        "  mst_b = 186\n",
        "  distancia = math.sqrt(((mst_r - r)** 2) + ((mst_g - g)**2) + ((mst_b - b)**2))\n",
        "  list_distance.append(distancia)\n",
        "  print(\"4\",distancia)\n",
        "  # elif (mst == 5):\n",
        "  mst_rgb = \"215, 189, 150\"\n",
        "  mst_r = 215\n",
        "  mst_g = 189\n",
        "  mst_b = 150\n",
        "  distancia = math.sqrt(((mst_r - r)** 2) + ((mst_g - g)**2) + ((mst_b - b)**2))\n",
        "  list_distance.append(distancia)\n",
        "  print(\"5\",distancia)\n",
        "  # elif (mst == 6):\n",
        "  mst_rgb = \"160, 126, 86\"\n",
        "  mst_r = 160\n",
        "  mst_g = 126\n",
        "  mst_b = 86\n",
        "  distancia = math.sqrt(((mst_r - r)** 2) + ((mst_g - g)**2) + ((mst_b - b)**2))\n",
        "  list_distance.append(distancia)\n",
        "  print(\"6\",distancia)\n",
        "  # elif (mst == 7):\n",
        "  mst_rgb = \"130, 92, 67\"\n",
        "  mst_r = 130\n",
        "  mst_g = 92\n",
        "  mst_b = 67\n",
        "  distancia = math.sqrt(((mst_r - r)** 2) + ((mst_g - g)**2) + ((mst_b - b)**2))\n",
        "  list_distance.append(distancia)\n",
        "  print(\"7\",distancia)\n",
        "  # elif (mst == 8):\n",
        "  mst_rgb = \"96, 65, 52\"\n",
        "  mst_r = 96\n",
        "  mst_g = 65\n",
        "  mst_b = 52\n",
        "  distancia = math.sqrt(((mst_r - r)** 2) + ((mst_g - g)**2) + ((mst_b - b)**2))\n",
        "  list_distance.append(distancia)\n",
        "  print(\"8\",distancia)\n",
        "  # elif (mst == 9):\n",
        "  mst_rgb = \"58, 49, 42\"\n",
        "  mst_r = 58\n",
        "  mst_g = 49\n",
        "  mst_b = 42\n",
        "  distancia = math.sqrt(((mst_r - r)** 2) + ((mst_g - g)**2) + ((mst_b - b)**2))\n",
        "  list_distance.append(distancia)\n",
        "  print(\"9\",distancia)\n",
        "  #  if(mst == 10):\n",
        "  mst_rgb = \"41, 36, 32\"\n",
        "  mst_r = 41\n",
        "  mst_g = 36\n",
        "  mst_b = 32\n",
        "  distancia = math.sqrt(((mst_r - r)** 2) + ((mst_g - g)**2) + ((mst_b - b)**2))\n",
        "  list_distance.append(distancia)\n",
        "  print(\"10\", distancia)\n",
        "  return list_distance"
      ],
      "metadata": {
        "id": "Wji9heMfVfgE"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage import data\n",
        "import numpy as np\n",
        "import colour\n",
        "import skimage.color\n",
        "list_distance_lab = []\n",
        "\n",
        "def get_lab_color(lab, mst):\n",
        "  list_distance_lab.clear()\n",
        "  #Monk Palette colors in Lab\n",
        "# else : #(mst == 1)\n",
        "  mst_lab = np.array([94.211, 1.503, 5.422])\n",
        "  distance_cie2000 = skimage.color.deltaE_ciede2000(mst_lab, lab)\n",
        "  list_distance_lab.append(distance_cie2000)\n",
        "  print(\"1\",distance_cie2000)\n",
        "# elif (mst == 2):\n",
        "  mst_lab = np.array([92.275, 2.061, 7.28])\n",
        "  distance_cie2000 = skimage.color.deltaE_ciede2000(mst_lab, lab)\n",
        "  list_distance_lab.append(distance_cie2000)\n",
        "  print(\"2\",distance_cie2000)\n",
        "# elif (mst == 3):\n",
        "  mst_lab = np.array([93.091, 0.216, 14.205])\n",
        "  distance_cie2000 = skimage.color.deltaE_ciede2000(mst_lab, lab)\n",
        "  list_distance_lab.append(distance_cie2000)\n",
        "  print(\"3\",distance_cie2000)\n",
        "# elif (mst == 4):\n",
        "  mst_lab = np.array([87.573, 0.459, 17.748])\n",
        "  distance_cie2000 = skimage.color.deltaE_ciede2000(mst_lab, lab)\n",
        "  list_distance_lab.append(distance_cie2000)\n",
        "  print(\"4\",distance_cie2000)\n",
        "# elif (mst == 5):\n",
        "  mst_lab = np.array([77.902, 3.471, 23.136])\n",
        "  distance_cie2000 = skimage.color.deltaE_ciede2000(mst_lab, lab)\n",
        "  list_distance_lab.append(distance_cie2000)\n",
        "  print(\"5\",distance_cie2000)\n",
        "# elif (mst == 6):\n",
        "  mst_lab = np.array([55.142, 7.783, 26.74])\n",
        "  distance_cie2000 = skimage.color.deltaE_ciede2000(mst_lab, lab)\n",
        "  list_distance_lab.append(distance_cie2000)\n",
        "  print(\"6\",distance_cie2000)\n",
        "# elif (mst == 7):\n",
        "  mst_lab = np.array([42.47, 12.325, 20.53])\n",
        "  distance_cie2000 = skimage.color.deltaE_ciede2000(mst_lab, lab)\n",
        "  list_distance_lab.append(distance_cie2000)\n",
        "  print(\"7\",distance_cie2000)\n",
        "# elif (mst == 8):\n",
        "  mst_lab = np.array([30.678, 11.667, 13.335])\n",
        "  distance_cie2000 = skimage.color.deltaE_ciede2000(mst_lab, lab)\n",
        "  list_distance_lab.append(distance_cie2000)\n",
        "  print(\"8\",distance_cie2000)\n",
        "# elif (mst == 9):\n",
        "  mst_lab = np.array([21.069, 2.69, 5.964])\n",
        "  distance_cie2000 = skimage.color.deltaE_ciede2000(mst_lab, lab)\n",
        "  list_distance_lab.append(distance_cie2000)\n",
        "  print(\"9\",distance_cie2000)\n",
        " # if(mst == 10):\n",
        "  mst_lab = np.array([14.61, 1.482, 3.525])\n",
        "  distance_cie2000 = skimage.color.deltaE_ciede2000(mst_lab, lab)\n",
        "  list_distance_lab.append(distance_cie2000)\n",
        "  print(\"10\",distance_cie2000)\n",
        "\n",
        "  return list_distance_lab"
      ],
      "metadata": {
        "id": "jAznr9GI95Ou"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U7d_APvx9n4Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "outputId": "77cc4998-012b-4dc5-8ce0-245d6a620a54"
      },
      "cell_type": "code",
      "source": [
        "from cv2 import imread\n",
        "import dlib\n",
        "from imutils import paths\n",
        "import pandas as pd\n",
        "import csv\n",
        "import math\n",
        "from colormath import color_diff_matrix\n",
        "\n",
        "# Get Image from path\n",
        "path = (\"/content/subject00/\")\n",
        "\n",
        "imagePaths = list(paths.list_images(path))\n",
        "for imagePath in imagePaths:\n",
        "    input_image = cv2.imread(imagePath)\n",
        "    print(imagePath)\n",
        "    image = imutils.resize(input_image, width=250)\n",
        "\n",
        "    #Show image\n",
        "    plt.imshow(cv2.cvtColor(image,cv2.COLOR_BGR2RGB))\n",
        "    plt.show()\n",
        "\n",
        "    # Apply Skin Mask\n",
        "    skin = extractSkin(image)\n",
        "\n",
        "    # Find the dominant color. Default is 1 , pass the parameter 'number_of_colors=N' where N is the specified number of colors\n",
        "    dominantColors = extractDominantColor(skin,hasThresholding=True)\n",
        "    print(dominantColors[0])\n",
        "\n",
        "    #Show in the dominant color information\n",
        "    # print(\"Color Information\")\n",
        "    # prety_print_data(dominantColors)\n",
        "\n",
        "    #Show in the dominant color as bar\n",
        "    print(\"Color Bar\")\n",
        "    colour_bar = plotColorBar(dominantColors)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(colour_bar)\n",
        "    plt.show()\n",
        "\n",
        "    #check CSV created\n",
        "    dataset = pd.read_csv(\"/content/dataset_details.csv\")\n",
        "    #return values from csv\n",
        "    image_name = imagePath.replace(path, '')\n",
        "\n",
        "    #return first dominant color\n",
        "    color = dominantColors[0]\n",
        "    print( 'color',color)\n",
        "\n",
        "    #return rgb color from dominat color\n",
        "    rgb, r, g, b = get_rgb_color(color)\n",
        "    bgr = cv2.cvtColor( np.uint8([[rgb]] ), cv2.COLOR_RGB2BGR)[0][0]\n",
        "    lab = cv2.cvtColor( np.uint8([[bgr]] ), cv2.COLOR_BGR2LAB)[0][0]\n",
        "    print('lab', lab)\n",
        "\n",
        "    #return mst color Monk classification\n",
        "    img = dataset.loc[dataset['image_ID'] == image_name]\n",
        "    mst = pd.DataFrame.from_dict(img.MST)\n",
        "    mst = str(mst)\n",
        "    mst = mst[13:17]\n",
        "    mst = int(mst)\n",
        "    print('mst', mst)\n",
        "\n",
        "    #return subject information\n",
        "    subject = pd.DataFrame.from_dict(img.subject_name)\n",
        "    subject = str(subject)\n",
        "    subject = subject[20:33]\n",
        "    print('subject',subject)\n",
        "\n",
        "    #return light informaton\n",
        "    light = pd.DataFrame.from_dict(img.lighting)\n",
        "    light = str(light)\n",
        "    light = light[17:30]\n",
        "    print('light',light)\n",
        "\n",
        "    list_distance = []\n",
        "    list_distance = get_distances(r, g, b)\n",
        "\n",
        "    print(\"list\", list_distance)\n",
        "\n",
        "    minimo = min(list_distance)\n",
        "    print(\"minimo\",minimo)\n",
        "    classificacao_indicada = 0\n",
        "    classificacao_indicada = list_distance.index(minimo)\n",
        "    #adjust classification to correspond mast list\n",
        "    classificacao_indicada = classificacao_indicada + 1\n",
        "    print('indicado rgb:', classificacao_indicada)\n",
        "\n",
        "    classificacao_mst = 0\n",
        "    classificacao_mst = list_distance[mst-1]\n",
        "    print('classificao mst', classificacao_mst)\n",
        "\n",
        "    list_lab = []\n",
        "    list_lab = get_lab_color(lab, mst)\n",
        "    print('result_lab', list_lab)\n",
        "    minimo_lab = min(list_lab)\n",
        "    print(\"minimo\",minimo_lab)\n",
        "    classificacao_indicada_lab = 0\n",
        "    classificacao_indicada_lab = list_lab.index(minimo_lab)\n",
        "    #adjust classification to correspond mast list\n",
        "    classificacao_indicada_lab = classificacao_indicada_lab + 1\n",
        "    print('indicado lab:', classificacao_indicada_lab)\n",
        "\n",
        "    if (dataset.image_ID == image_name).any() == True:\n",
        "    #Monk Palette colors in RGB\n",
        "      if(mst == 10):\n",
        "        mst_rgb = \"41, 36, 32\"\n",
        "        mst_r = 41\n",
        "        mst_g = 36\n",
        "        mst_b = 32\n",
        "        mst_lab = np.array([14.61, 1.482, 3.525])\n",
        "      elif (mst == 9):\n",
        "        mst_rgb = \"58, 49, 42\"\n",
        "        mst_r = 58\n",
        "        mst_g = 49\n",
        "        mst_b = 42\n",
        "        mst_lab = np.array([21.069, 2.69, 5.964])\n",
        "      elif (mst == 8):\n",
        "        mst_rgb = \"96, 65, 52\"\n",
        "        mst_r = 96\n",
        "        mst_g = 65\n",
        "        mst_b = 52\n",
        "        mst_lab = np.array([30.678, 11.667, 13.335])\n",
        "      elif (mst == 7):\n",
        "        mst_rgb = \"130, 92, 67\"\n",
        "        mst_r = 130\n",
        "        mst_g = 92\n",
        "        mst_b = 67\n",
        "        mst_lab = np.array([42.47, 12.325, 20.53])\n",
        "      elif (mst == 6):\n",
        "        mst_rgb = \"160, 126, 86\"\n",
        "        mst_r = 160\n",
        "        mst_g = 126\n",
        "        mst_b = 86\n",
        "        mst_lab = np.array([55.142, 7.783, 26.74])\n",
        "      elif (mst == 5):\n",
        "        mst_rgb = \"215, 189, 150\"\n",
        "        mst_r = 215\n",
        "        mst_g = 189\n",
        "        mst_b = 150\n",
        "        mst_lab = np.array([77.902, 3.471, 23.136])\n",
        "      elif (mst == 4):\n",
        "        mst_rgb = \"234, 218, 186\"\n",
        "        mst_r = 234\n",
        "        mst_g = 218\n",
        "        mst_b = 186\n",
        "        mst_lab = np.array([87.573, 0.459, 17.748])\n",
        "      elif (mst == 3):\n",
        "        mst_rgb = \"247, 234, 208\"\n",
        "        mst_r = 247\n",
        "        mst_g = 234\n",
        "        mst_b = 208\n",
        "        mst_lab = np.array([93.091, 0.216, 14.205])\n",
        "      elif (mst == 2):\n",
        "        mst_rgb = \"243, 231, 219\"\n",
        "        mst_r = 243\n",
        "        mst_g = 231\n",
        "        mst_b = 219\n",
        "        mst_lab = np.array([92.275, 2.061, 7.28])\n",
        "      else : #(mst == 1)\n",
        "        mst_rgb = \"246, 237, 228\"\n",
        "        mst_r = 246\n",
        "        mst_g = 237\n",
        "        mst_b = 228\n",
        "        mst_lab = np.array([94.211, 1.503, 5.422])\n",
        "    distance_rgb = math.sqrt(((mst_r - r)** 2) + ((mst_g - g)**2) + ((mst_b - b)**2))\n",
        "    distance_lab = skimage.color.deltaE_ciede2000(mst_lab, lab)\n",
        "    print('distance rgb',distance_rgb)\n",
        "    print('distance lab',distance_lab)\n",
        "\n",
        "    accuracy = round(100 - distance_lab, 2)\n",
        "    print(accuracy, 'accuracy')\n",
        "    with open('dataset_details_answer.csv', 'a', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow([image_name, subject, light, mst, mst_rgb, rgb, lab, distance_rgb, minimo, classificacao_indicada, distance_lab, minimo_lab, classificacao_indicada_lab])\n"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-89-e72af077c6f1>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mimutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl_to_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://github.com/vittoria-thomasini/Extract_skintone_image/tree/d0204acb6db7150fa467bc67fcd02d43b0595626/subject_0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mimagePaths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimagePath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimagePaths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0minput_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimagePath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/imutils/paths.py\u001b[0m in \u001b[0;36mlist_files\u001b[0;34m(basePath, validExts, contains)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlist_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasePath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidExts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontains\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# loop over the directory structure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrootDir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirNames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasePath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;31m# loop over the filenames in the current directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/os.py\u001b[0m in \u001b[0;36mwalk\u001b[0;34m(top, topdown, onerror, followlinks)\u001b[0m\n\u001b[1;32m    341\u001b[0m     \"\"\"\n\u001b[1;32m    342\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"os.walk\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopdown\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monerror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollowlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_walk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopdown\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monerror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollowlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_walk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopdown\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monerror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollowlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not NoneType"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "hNMUSCyGgp8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from cv2 import imread\n",
        "# import dlib\n",
        "# from imutils import paths\n",
        "# import pandas as pd\n",
        "# import csv\n",
        "# import math\n",
        "\n",
        "#   # Get Image from URL. If you want to upload an image file and use that comment the below code and replace with  image=cv2.imread(\"FILE_NAME\")\n",
        "#   #\n",
        "# # input_image =  imutils.url_to_image(\"https://raw.githubusercontent.com/vittoria-thomasini/Extract_skintone_image/main/terry.jpg\")\n",
        "# # # image =  imutils.url_to_image(\"https://raw.githubusercontent.com/vittoria-thomasini/Extract_skintone_image/main/jolie.jpg\")\n",
        "# # input_image =  imutils.url_to_image(\"https://raw.githubusercontent.com/vittoria-thomasini/Extract_skintone_image/main/terry.jpg\")\n",
        "# # input_image = imread(\"/content/PXL_20220922_174011830.jpg\")\n",
        "# # path = (\"/content/subject01\")\n",
        "\n",
        "# # imagePaths = list(paths.list_images(path))\n",
        "# # for imagePath in imagePaths:\n",
        "# #     input_image = cv2.imread(imagePath)\n",
        "# #     print(imagePath)\n",
        "# image = imutils.resize(input_image, width=250)\n",
        "\n",
        "# #Show image\n",
        "# plt.imshow(cv2.cvtColor(image,cv2.COLOR_BGR2RGB))\n",
        "# plt.show()\n",
        "\n",
        "# # Apply Skin Mask\n",
        "# skin = extractSkin(image)\n",
        "\n",
        "# # Find the dominant color. Default is 1 , pass the parameter 'number_of_colors=N' where N is the specified number of colors\n",
        "# dominantColors = extractDominantColor(skin,hasThresholding=True)\n",
        "# print(dominantColors[0])\n",
        "\n",
        "# #Show in the dominant color information\n",
        "# # print(\"Color Information\")\n",
        "# # prety_print_data(dominantColors)\n",
        "\n",
        "# #Show in the dominant color as bar\n",
        "# print(\"Color Bar\")\n",
        "# colour_bar = plotColorBar(dominantColors)\n",
        "# plt.axis(\"off\")\n",
        "# plt.imshow(colour_bar)\n",
        "# plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# #check CSV created\n",
        "# dataset = pd.read_csv(\"/content/dataset_details.csv\")\n",
        "# #return values from csv\n",
        "# image_name = 'PXL_20220922_174011830.jpg'\n",
        "\n",
        "# img = dataset.loc[dataset['image_ID'] == image_name]\n",
        "\n",
        "# color = dominantColors[0]\n",
        "# df = pd.DataFrame.from_dict(color)\n",
        "# r = df.loc[0, 'color']\n",
        "# r = str(r)\n",
        "# print(r)\n",
        "# b = df.loc[1, 'color']\n",
        "# b = str(b)\n",
        "# print(b)\n",
        "# g = df.loc[2, 'color']\n",
        "# g = str(g)\n",
        "# print(g)\n",
        "# rgb =  r + ',' + g + ',' + b\n",
        "# # print(rgb)\n",
        "# mst = pd.DataFrame.from_dict(img.MST)\n",
        "# mst = str(mst)\n",
        "# mst = mst[15:17]\n",
        "# print(mst)\n",
        "\n",
        "# subject = pd.DataFrame.from_dict(img.subject_name)\n",
        "# subject = str(subject)\n",
        "# subject = subject[23:33]\n",
        "# print(subject)\n",
        "# r = float(r)\n",
        "# g = float(g)\n",
        "# b = float(b)\n",
        "\n",
        "\n",
        "# #  if(mst == 10):\n",
        "# mst_rgb = \"41, 36, 32\"\n",
        "# mst_r = 41\n",
        "# mst_g = 36\n",
        "# mst_b = 32\n",
        "# distancia = math.sqrt(((mst_r - r)** 2) + ((mst_g - g)**2) + ((mst_b - b)**2))\n",
        "# print(distancia)\n",
        "# # elif (mst == 9):\n",
        "# mst_rgb = \"58, 49, 42\"\n",
        "# mst_r = 58\n",
        "# mst_g = 49\n",
        "# mst_b = 42\n",
        "# distancia = math.sqrt(((mst_r - r)** 2) + ((mst_g - g)**2) + ((mst_b - b)**2))\n",
        "# print(distancia)\n",
        "# # elif (mst == 8):\n",
        "# mst_rgb = \"96, 65, 52\"\n",
        "# mst_r = 96\n",
        "# mst_g = 65\n",
        "# mst_b = 52\n",
        "# distancia = math.sqrt(((mst_r - r)** 2) + ((mst_g - g)**2) + ((mst_b - b)**2))\n",
        "# print(distancia)\n",
        "# # elif (mst == 7):\n",
        "# mst_rgb = \"130, 92, 67\"\n",
        "# mst_r = 130\n",
        "# mst_g = 92\n",
        "# mst_b = 67\n",
        "# distancia = math.sqrt(((mst_r - r)** 2) + ((mst_g - g)**2) + ((mst_b - b)**2))\n",
        "# print(distancia)\n",
        "# # elif (mst == 6):\n",
        "# mst_rgb = \"160, 126, 86\"\n",
        "# mst_r = 160\n",
        "# mst_g = 126\n",
        "# mst_b = 86\n",
        "# distancia = math.sqrt(((mst_r - r)** 2) + ((mst_g - g)**2) + ((mst_b - b)**2))\n",
        "# print(distancia)\n",
        "# # elif (mst == 5):\n",
        "# mst_rgb = \"215, 189, 150\"\n",
        "# mst_r = 215\n",
        "# mst_g = 189\n",
        "# mst_b = 150\n",
        "# distancia = math.sqrt(((mst_r - r)** 2) + ((mst_g - g)**2) + ((mst_b - b)**2))\n",
        "# print(distancia)\n",
        "# # elif (mst == 4):\n",
        "# mst_rgb = \"234, 218, 186\"\n",
        "# mst_r = 234\n",
        "# mst_g = 218\n",
        "# mst_b = 186\n",
        "# distancia = math.sqrt(((mst_r - r)** 2) + ((mst_g - g)**2) + ((mst_b - b)**2))\n",
        "# print(distancia)\n",
        "# # elif (mst == 3):\n",
        "# mst_rgb = \"247, 234, 208\"\n",
        "# mst_r = 247\n",
        "# mst_g = 234\n",
        "# mst_b = 208\n",
        "# distancia = math.sqrt(((mst_r - r)** 2) + ((mst_g - g)**2) + ((mst_b - b)**2))\n",
        "# print(distancia)\n",
        "# # elif (mst == 2):\n",
        "# mst_rgb = \"243, 231, 219\"\n",
        "# mst_r = 243\n",
        "# mst_g = 231\n",
        "# mst_b = 219\n",
        "# distancia = math.sqrt(((mst_r - r)** 2) + ((mst_g - g)**2) + ((mst_b - b)**2))\n",
        "# print(distancia)\n",
        "# # else : #(mst == 1)\n",
        "# mst_rgb = \"246, 237, 228\"\n",
        "# mst_r = 246\n",
        "# mst_g = 237\n",
        "# mst_b = 228\n",
        "# distancia = math.sqrt(((mst_r - r)** 2) + ((mst_g - g)**2) + ((mst_b - b)**2))\n",
        "# print(distancia)\n",
        "\n",
        "# if (dataset.image_ID == image_name).any() == True:\n",
        "# #Monk Palette colors in RGB\n",
        "#   if(mst == 10):\n",
        "#     mst_rgb = \"41, 36, 32\"\n",
        "#     mst_r = 41\n",
        "#     mst_g = 36\n",
        "#     mst_b = 32\n",
        "#   elif (mst == 9):\n",
        "#     mst_rgb = \"58, 49, 42\"\n",
        "#     mst_r = 58\n",
        "#     mst_g = 49\n",
        "#     mst_b = 42\n",
        "#   elif (mst == 8):\n",
        "#     mst_rgb = \"96, 65, 52\"\n",
        "#     mst_r = 96\n",
        "#     mst_g = 65\n",
        "#     mst_b = 52\n",
        "#   elif (mst == 7):\n",
        "#     mst_rgb = \"130, 92, 67\"\n",
        "#     mst_r = 130\n",
        "#     mst_g = 92\n",
        "#     mst_b = 67\n",
        "#   elif (mst == 6):\n",
        "#     mst_rgb = \"160, 126, 86\"\n",
        "#     mst_r = 160\n",
        "#     mst_g = 126\n",
        "#     mst_b = 86\n",
        "#   elif (mst == 5):\n",
        "#     mst_rgb = \"215, 189, 150\"\n",
        "#     mst_r = 215\n",
        "#     mst_g = 189\n",
        "#     mst_b = 150\n",
        "#   elif (mst == 4):\n",
        "#     mst_rgb = \"234, 218, 186\"\n",
        "#     mst_r = 234\n",
        "#     mst_g = 218\n",
        "#     mst_b = 186\n",
        "#   elif (mst == 3):\n",
        "#     mst_rgb = \"247, 234, 208\"\n",
        "#     mst_r = 247\n",
        "#     mst_g = 234\n",
        "#     mst_b = 208\n",
        "#   elif (mst == 2):\n",
        "#     mst_rgb = \"243, 231, 219\"\n",
        "#     mst_r = 243\n",
        "#     mst_g = 231\n",
        "#     mst_b = 219\n",
        "#   else : #(mst == 1)\n",
        "#     mst_rgb = \"246, 237, 228\"\n",
        "#     mst_r = 246\n",
        "#     mst_g = 237\n",
        "#     mst_b = 228\n",
        "\n",
        "# distancia = math.sqrt(((mst_r - r)** 2) + ((mst_g - g)**2) + ((mst_b - b)**2))\n",
        "# print(\"distancia\", distancia)\n",
        "\n",
        "# with open('dataset_details_answer.csv', 'a', newline='') as file:\n",
        "#     writer = csv.writer(file)\n",
        "#     writer.writerow([image_name, subject, mst, mst_rgb, mst_r, mst_g, mst_b, rgb,  r, g, b])\n"
      ],
      "metadata": {
        "id": "0Olu7CNKoJ0x"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://python-colormath.readthedocs.io/en/latest/_modules/colormath/color_diff.html#delta_e_cie2000"
      ],
      "metadata": {
        "id": "PWDFUd_ZYyU9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.color.delta_e import deltaE_ciede2000\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "The functions in this module are used for comparing two LabColor objects\n",
        "using various Delta E formulas.\n",
        "\"\"\"\n",
        "\n",
        "import numpy\n",
        "\n",
        "from colormath import color_diff_matrix\n",
        "\n",
        "color1 = np.array([93.091, 0.216, 14.205])\n",
        "def _get_lab_color1_vector(color1):\n",
        "    \"\"\"\n",
        "    Converts an LabColor into a NumPy vector.\n",
        "\n",
        "    :param LabColor color:\n",
        "    :rtype: numpy.ndarray\n",
        "    \"\"\"\n",
        "    if not color.__class__.__name__ == 'LabColor':\n",
        "        raise ValueError(\n",
        "            \"Delta E functions can only be used with two LabColor objects.\")\n",
        "    return numpy.array([color.lab_l, color.lab_a, color.lab_b])\n",
        "\n",
        "color2 = np.array([ 53, 128, 128])\n",
        "def _get_lab_color2_matrix(COLOR_BGR2LAB):\n",
        "    \"\"\"\n",
        "    Converts an LabColor into a NumPy matrix.\n",
        "\n",
        "    :param LabColor color:\n",
        "    :rtype: numpy.ndarray\n",
        "    \"\"\"\n",
        "    if not color.__class__.__name__ == 'LabColor':\n",
        "        raise ValueError(\n",
        "            \"Delta E functions can only be used with two LabColor objects.\")\n",
        "    return numpy.array([(color.lab_l, color.lab_a, color.lab_b)])\n",
        "\n",
        "\n",
        "# noinspection PyPep8Naming\n",
        "def delta_e_cie1976(color1, color2):\n",
        "    \"\"\"\n",
        "    Calculates the Delta E (CIE1976) of two colors.\n",
        "    \"\"\"\n",
        "    color1_vector = _get_lab_color1_vector(color1)\n",
        "    color2_matrix = _get_lab_color2_matrix(color2)\n",
        "    delta_e = color_diff_matrix.delta_e_cie1976(color1_vector, color2_matrix)[0]\n",
        "    return numpy.asscalar(delta_e)\n",
        "\n",
        "\n",
        "\n",
        "# noinspection PyPep8Naming\n",
        "def delta_e_cie1994(color1, color2, K_L=1, K_C=1, K_H=1, K_1=0.045, K_2=0.015):\n",
        "    \"\"\"\n",
        "    Calculates the Delta E (CIE1994) of two colors.\n",
        "\n",
        "    K_l:\n",
        "      0.045 graphic arts\n",
        "      0.048 textiles\n",
        "    K_2:\n",
        "      0.015 graphic arts\n",
        "      0.014 textiles\n",
        "    K_L:\n",
        "      1 default\n",
        "      2 textiles\n",
        "    \"\"\"\n",
        "    color1_vector = _get_lab_color1_vector(color1)\n",
        "    color2_matrix = _get_lab_color2_matrix(color2)\n",
        "    delta_e = color_diff_matrix.delta_e_cie1994(\n",
        "        color1_vector, color2_matrix, K_L=K_L, K_C=K_C, K_H=K_H, K_1=K_1, K_2=K_2)[0]\n",
        "    return numpy.asscalar(delta_e)\n",
        "\n",
        "\n",
        "\n",
        "# noinspection PyPep8Naming\n",
        "def delta_e_cie2000(color1, color2, Kl=1, Kc=1, Kh=1):\n",
        "    \"\"\"\n",
        "    Calculates the Delta E (CIE2000) of two colors.\n",
        "    \"\"\"\n",
        "    color1_vector = _get_lab_color1_vector(color1)\n",
        "    color2_matrix = _get_lab_color2_matrix(color2)\n",
        "    delta_e = color_diff_matrix.delta_e_cie2000(\n",
        "        color1_vector, color2_matrix, Kl=Kl, Kc=Kc, Kh=Kh)[0]\n",
        "    return numpy.asscalar(delta_e)\n",
        "\n",
        "\n",
        "\n",
        "# noinspection PyPep8Naming\n",
        "def delta_e_cmc(color1, color2, pl=2, pc=1):\n",
        "    \"\"\"\n",
        "    Calculates the Delta E (CMC) of two colors.\n",
        "\n",
        "    CMC values\n",
        "      Acceptability: pl=2, pc=1\n",
        "      Perceptability: pl=1, pc=1\n",
        "    \"\"\"\n",
        "    color1_vector = _get_lab_color1_vector(color1)\n",
        "    color2_matrix = _get_lab_color2_matrix(color2)\n",
        "    delta_e = color_diff_matrix.delta_e_cmc(\n",
        "        color1_vector, color2_matrix, pl=pl, pc=pc)[0]\n",
        "    return numpy.asscalar(delta_e)\n",
        "\n",
        "# cie1976 = delta_e_cie1976(color1, color2)\n",
        "# print(cie1976)\n",
        "# cie1994 = delta_e_cie1994(color1, color2, 1,1,1)\n",
        "# print(cie1994)\n",
        "cie2000 = deltaE_ciede2000(color1, color2, 1,1,1)\n",
        "print(cie2000)\n",
        "# cmc = delta_e_cmc(color1, color2, 1,1,1)\n",
        "# print(cmc)\n",
        "distance_lab1 = skimage.color.deltaE_ciede2000(color1, color2)\n",
        "print(distance_lab1)\n",
        "distance_lab2 = skimage.color.deltaE_ciede2000(color2, color1)\n",
        "print(distance_lab2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zy_cvUvkSZkq",
        "outputId": "d2cc8fa8-caf8-48b5-9776-b44ca5e513dc"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47.62832322604536\n",
            "47.62832322604536\n",
            "47.62832322604536\n"
          ]
        }
      ]
    }
  ]
}